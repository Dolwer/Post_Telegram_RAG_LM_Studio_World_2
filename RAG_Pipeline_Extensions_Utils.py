import os
import json
import csv
import requests
from typing import List, Dict, Optional, Generator
from pathlib import Path
import asyncio
import aiohttp
from dataclasses import dataclass
import xml.etree.ElementTree as ET
from urllib.parse import urlparse, urljoin
import time
import hashlib

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ (—É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
try:
    import PyPDF2
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    print("PyPDF2 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å PDF –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")

try:
    from bs4 import BeautifulSoup
    BS4_AVAILABLE = True
except ImportError:
    BS4_AVAILABLE = False
    print("BeautifulSoup4 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")

try:
    import docx
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    print("python-docx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å DOCX –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")

from advanced_rag_pipeline import Document, AdvancedRAGPipeline

class DataIngestionManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    
    def __init__(self, rag_pipeline: AdvancedRAGPipeline):
        self.rag = rag_pipeline
    
    def load_from_text_file(self, filepath: str, encoding: str = 'utf-8') -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            with open(filepath, 'r', encoding=encoding) as f:
                return f.read()
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {filepath}: {e}")
    
    def load_from_pdf(self, filepath: str) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF —Ñ–∞–π–ª–∞"""
        if not PDF_AVAILABLE:
            raise Exception("PyPDF2 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install PyPDF2")
        
        try:
            text = ""
            with open(filepath, 'rb') as f:
                reader = PyPDF2.PdfReader(f)
                for page in reader.pages:
                    text += page.extract_text() + "\n"
            return text
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF {filepath}: {e}")
    
    def load_from_docx(self, filepath: str) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∏–∑ DOCX —Ñ–∞–π–ª–∞"""
        if not DOCX_AVAILABLE:
            raise Exception("python-docx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install python-docx")
        
        try:
            doc = docx.Document(filepath)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            return text
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è DOCX {filepath}: {e}")
    
    def load_from_csv(self, filepath: str, text_columns: List[str]) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV —Ñ–∞–π–ª–∞"""
        try:
            documents = []
            with open(filepath, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for i, row in enumerate(reader):
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç
                    content_parts = []
                    for col in text_columns:
                        if col in row and row[col]:
                            content_parts.append(str(row[col]))
                    
                    if content_parts:
                        content = " ".join(content_parts)
                        # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∫–∞–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                        metadata = {k: v for k, v in row.items() if k not in text_columns}
                        
                        documents.append({
                            'id': f"csv_row_{i}",
                            'content': content,
                            'metadata': metadata
                        })
            
            return documents
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è CSV {filepath}: {e}")
    
    def load_from_json(self, filepath: str, content_field: str, id_field: Optional[str] = None) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            documents = []
            if isinstance(data, list):
                for i, item in enumerate(data):
                    if content_field in item:
                        doc_id = item.get(id_field, f"json_item_{i}") if id_field else f"json_item_{i}"
                        content = str(item[content_field])
                        metadata = {k: v for k, v in item.items() if k not in [content_field, id_field]}
                        
                        documents.append({
                            'id': doc_id,
                            'content': content,
                            'metadata': metadata
                        })
            
            return documents
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è JSON {filepath}: {e}")
    
    def load_from_url(self, url: str, timeout: int = 30) -> str:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å URL"""
        try:
            response = requests.get(url, timeout=timeout)
            response.raise_for_status()
            
            # –ï—Å–ª–∏ —ç—Ç–æ HTML, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç
            if 'text/html' in response.headers.get('content-type', ''):
                if BS4_AVAILABLE:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    # –£–¥–∞–ª—è–µ–º script –∏ style —Ç–µ–≥–∏
                    for script in soup(["script", "style"]):
                        script.decompose()
                    return soup.get_text()
                else:
                    return response.text
            else:
                return response.text
                
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ URL {url}: {e}")
    
    async def load_from_urls_async(self, urls: List[str], timeout: int = 30) -> List[Dict]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ URL"""
        async def fetch_url(session, url):
            try:
                async with session.get(url, timeout=timeout) as response:
                    content = await response.text()
                    if 'text/html' in response.headers.get('content-type', ''):
                        if BS4_AVAILABLE:
                            soup = BeautifulSoup(content, 'html.parser')
                            for script in soup(["script", "style"]):
                                script.decompose()
                            content = soup.get_text()
                    
                    return {
                        'id': hashlib.md5(url.encode()).hexdigest(),
                        'content': content,
                        'metadata': {'source_url': url, 'status': 'success'}
                    }
            except Exception as e:
                return {
                    'id': hashlib.md5(url.encode()).hexdigest(),
                    'content': "",
                    'metadata': {'source_url': url, 'status': 'error', 'error': str(e)}
                }
        
        async with aiohttp.ClientSession() as session:
            tasks = [fetch_url(session, url) for url in urls]
            results = await asyncio.gather(*tasks)
            return [r for r in results if r['content']]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ —É—Å–ø–µ—à–Ω—ã–µ

class RAGAnalytics:
    """–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ RAG —Å–∏—Å—Ç–µ–º—ã"""
    
    def __init__(self, rag_pipeline: AdvancedRAGPipeline):
        self.rag = rag_pipeline
        self.query_log = []
    
    def log_query(self, query: str, results_count: int, processing_time: float):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞"""
        self.query_log.append({
            'timestamp': time.time(),
            'query': query,
            'results_count': results_count,
            'processing_time': processing_time
        })
    
    def get_query_stats(self) -> Dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º"""
        if not self.query_log:
            return {"message": "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º"}
        
        processing_times = [log['processing_time'] for log in self.query_log]
        results_counts = [log['results_count'] for log in self.query_log]
        
        return {
            'total_queries': len(self.query_log),
            'avg_processing_time': sum(processing_times) / len(processing_times),
            'max_processing_time': max(processing_times),
            'min_processing_time': min(processing_times),
            'avg_results_count': sum(results_counts) / len(results_counts),
            'queries_per_hour': len([q for q in self.query_log if time.time() - q['timestamp'] < 3600])
        }
    
    def analyze_collection_content(self) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            all_data = self.rag.collection.get()
            documents = all_data.get('documents', [])
            metadatas = all_data.get('metadatas', [])
            
            if not documents:
                return {"message": "–ö–æ–ª–ª–µ–∫—Ü–∏—è –ø—É—Å—Ç–∞"}
            
            # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            total_docs = len(documents)
            total_chars = sum(len(doc) for doc in documents)
            avg_doc_length = total_chars / total_docs
            
            # –ê–Ω–∞–ª–∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            categories = {}
            languages = {}
            
            for metadata in metadatas:
                if metadata:
                    if 'category' in metadata:
                        cat = metadata['category']
                        categories[cat] = categories.get(cat, 0) + 1
                    
                    if 'language' in metadata:
                        lang = metadata['language']
                        languages[lang] = languages.get(lang, 0) + 1
            
            return {
                'total_documents': total_docs,
                'total_characters': total_chars,
                'average_document_length': avg_doc_length,
                'categories_distribution': categories,
                'languages_distribution': languages,
                'longest_document': max(len(doc) for doc in documents),
                'shortest_document': min(len(doc) for doc in documents)
            }
            
        except Exception as e:
            return {"error": f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}"}

class RAGWebInterface:
    """–ü—Ä–æ—Å—Ç–æ–π –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã"""
    
    def __init__(self, rag_pipeline: AdvancedRAGPipeline, analytics: RAGAnalytics):
        self.rag = rag_pipeline
        self.analytics = analytics
    
    def generate_html_interface(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
        html_template = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>RAG Pipeline Interface</title>
            <meta charset="UTF-8">
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }
                .container { max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; }
                .search-box { width: 70%; padding: 10px; font-size: 16px; border: 1px solid #ddd; border-radius: 4px; }
                .search-btn { padding: 10px 20px; background: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer; }
                .result { margin: 15px 0; padding: 15px; border: 1px solid #ddd; border-radius: 4px; background: #f9f9f9; }
                .score { color: #666; font-size: 14px; }
                .metadata { color: #888; font-size: 12px; margin-top: 5px; }
                .stats { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 20px 0; }
                .stat-card { padding: 15px; background: #e9ecef; border-radius: 4px; text-align: center; }
            </style>
        </head>
        <body>
            <div class="container">
                <h1>üîç RAG Pipeline Interface</h1>
                
                <div class="search-section">
                    <input type="text" class="search-box" id="searchInput" placeholder="–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å...">
                    <button class="search-btn" onclick="performSearch()">–ü–æ–∏—Å–∫</button>
                </div>
                
                <div id="results"></div>
                
                <h2>üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã</h2>
                <div class="stats" id="stats">
                    <div class="stat-card">
                        <h3>–ó–∞–ø—Ä–æ—Å—ã</h3>
                        <div id="queryCount">–ó–∞–≥—Ä—É–∑–∫–∞...</div>
                    </div>
                    <div class="stat-card">
                        <h3>–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è</h3>
                        <div id="avgTime">–ó–∞–≥—Ä—É–∑–∫–∞...</div>
                    </div>
                </div>
                
                <h2>üìà –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏</h2>
                <div style="margin: 20px 0;">
                    <button onclick="exportData()" style="margin-right: 10px; padding: 8px 16px; background: #28a745; color: white; border: none; border-radius: 4px;">–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö</button>
                    <button onclick="clearCollection()" style="padding: 8px 16px; background: #dc3545; color: white; border: none; border-radius: 4px;">–û—á–∏—Å—Ç–∏—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é</button>
                </div>
            </div>
            
            <script>
                async function performSearch() {
                    const query = document.getElementById('searchInput').value;
                    if (!query.trim()) return;
                    
                    const resultsDiv = document.getElementById('results');
                    resultsDiv.innerHTML = '<div>–ü–æ–∏—Å–∫...</div>';
                    
                    try {
                        // –ó–¥–µ—Å—å –±—É–¥–µ—Ç API –≤—ã–∑–æ–≤ –∫ —Å–µ—Ä–≤–µ—Ä—É RAG
                        // –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                        setTimeout(() => {
                            resultsDiv.innerHTML = `
                                <h3>–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è: "${query}"</h3>
                                <div class="result">
                                    <strong>–î–æ–∫—É–º–µ–Ω—Ç 1</strong>
                                    <div class="score">–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: 0.85</div>
                                    <p>–ü—Ä–∏–º–µ—Ä –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...</p>
                                    <div class="metadata">–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: category=ai, timestamp=2024-01-01</div>
                                </div>
                            `;
                        }, 1000);
                    } catch (error) {
                        resultsDiv.innerHTML = '<div style="color: red;">–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: ' + error.message + '</div>';
                    }
                }
                
                function loadStats() {
                    // –ó–¥–µ—Å—å –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                    document.getElementById('docCount').textContent = '150';
                    document.getElementById('queryCount').textContent = '45';
                    document.getElementById('avgTime').textContent = '0.3s';
                }
                
                function exportData() {
                    alert('–§—É–Ω–∫—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ');
                }
                
                function clearCollection() {
                    if (confirm('–í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –æ—á–∏—Å—Ç–∏—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é?')) {
                        alert('–§—É–Ω–∫—Ü–∏—è –æ—á–∏—Å—Ç–∫–∏ –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ');
                    }
                }
                
                // –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                window.onload = loadStats;
                
                // –ü–æ–∏—Å–∫ –ø–æ Enter
                document.getElementById('searchInput').addEventListener('keypress', function(e) {
                    if (e.key === 'Enter') {
                        performSearch();
                    }
                });
            </script>
        </body>
        </html>
        """
        return html_template
    
    def save_interface(self, filepath: str = "rag_interface.html"):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ HTML –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –≤ —Ñ–∞–π–ª"""
        html_content = self.generate_html_interface()
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(html_content)
        print(f"HTML –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {filepath}")

class RAGBenchmarking:
    """–ë–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ RAG —Å–∏—Å—Ç–µ–º—ã"""
    
    def __init__(self, rag_pipeline: AdvancedRAGPipeline):
        self.rag = rag_pipeline
    
    def create_test_dataset(self, size: int = 100) -> List[Document]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        test_topics = [
            "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "–Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏",
            "–≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö", "–æ–±—Ä–∞–±–æ—Ç–∫–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞",
            "–∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ", "–≥–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "–∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö",
            "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Python", "–≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞"
        ]
        
        documents = []
        for i in range(size):
            topic = test_topics[i % len(test_topics)]
            content = self._generate_synthetic_content(topic, i)
            
            doc = Document(
                id=f"test_doc_{i}",
                content=content,
                metadata={
                    "topic": topic,
                    "test_id": i,
                    "synthetic": True
                }
            )
            documents.append(doc)
        
        return documents
    
    def _generate_synthetic_content(self, topic: str, doc_id: int) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è —Ç–µ—Å—Ç–æ–≤"""
        templates = [
            f"{topic} —è–≤–ª—è–µ—Ç—Å—è –≤–∞–∂–Ω–æ–π –æ–±–ª–∞—Å—Ç—å—é —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏. –î–æ–∫—É–º–µ–Ω—Ç –Ω–æ–º–µ—Ä {doc_id} —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ {topic} –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ñ–µ—Ä–∞—Ö.",
            f"–í —ç—Ç–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç—Å—è –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã {topic}. –≠—Ç–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –Ω–æ–º–µ—Ä {doc_id} –ø–æ–º–æ–∂–µ—Ç –ø–æ–Ω—è—Ç—å –∫–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏.",
            f"–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ {topic} –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç—Å—è –≤ –ø—Ä–∏–º–µ—Ä–µ {doc_id}. –ó–¥–µ—Å—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –ª—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏ –º–µ—Ç–æ–¥—ã."
        ]
        
        base_content = templates[doc_id % len(templates)]
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
        additional = f" –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ –≤–∫–ª—é—á–∞—é—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã, –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤ –æ–±–ª–∞—Å—Ç–∏ {topic}."
        
        return base_content + additional
    
    def benchmark_search_performance(self, queries: List[str], n_runs: int = 10) -> Dict:
        """–ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞"""
        results = {
            'queries': [],
            'avg_time': 0,
            'total_time': 0,
            'fastest_query': None,
            'slowest_query': None
        }
        
        total_time = 0
        fastest_time = float('inf')
        slowest_time = 0
        
        for query in queries:
            query_times = []
            
            for _ in range(n_runs):
                start_time = time.time()
                search_results = self.rag.search(query, n_results=5)
                end_time = time.time()
                
                query_time = end_time - start_time
                query_times.append(query_time)
                total_time += query_time
            
            avg_query_time = sum(query_times) / len(query_times)
            min_query_time = min(query_times)
            max_query_time = max(query_times)
            
            if min_query_time < fastest_time:
                fastest_time = min_query_time
                results['fastest_query'] = query
            
            if max_query_time > slowest_time:
                slowest_time = max_query_time
                results['slowest_query'] = query
            
            results['queries'].append({
                'query': query,
                'avg_time': avg_query_time,
                'min_time': min_query_time,
                'max_time': max_query_time,
                'runs': n_runs
            })
        
        results['avg_time'] = total_time / (len(queries) * n_runs)
        results['total_time'] = total_time
        results['fastest_time'] = fastest_time
        results['slowest_time'] = slowest_time
        
        return results
    
    def evaluate_retrieval_quality(self, test_queries: List[Dict]) -> Dict:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞
        test_queries: [{'query': str, 'relevant_doc_ids': List[str]}]
        """
        metrics = {
            'precision_at_k': [],
            'recall_at_k': [],
            'average_precision': []
        }
        
        for test_case in test_queries:
            query = test_case['query']
            relevant_ids = set(test_case['relevant_doc_ids'])
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
            results = self.rag.search(query, n_results=10)
            retrieved_ids = [r.document_id for r in results]
            
            # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö K
            for k in [1, 3, 5, 10]:
                if k <= len(retrieved_ids):
                    retrieved_k = set(retrieved_ids[:k])
                    
                    # Precision@K
                    precision = len(retrieved_k & relevant_ids) / k
                    
                    # Recall@K
                    recall = len(retrieved_k & relevant_ids) / len(relevant_ids) if relevant_ids else 0
                    
                    metrics['precision_at_k'].append(precision)
                    metrics['recall_at_k'].append(recall)
            
            # Average Precision
            ap = self._calculate_average_precision(retrieved_ids, relevant_ids)
            metrics['average_precision'].append(ap)
        
        # –£—Å—Ä–µ–¥–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        final_metrics = {
            'mean_precision_at_k': sum(metrics['precision_at_k']) / len(metrics['precision_at_k']) if metrics['precision_at_k'] else 0,
            'mean_recall_at_k': sum(metrics['recall_at_k']) / len(metrics['recall_at_k']) if metrics['recall_at_k'] else 0,
            'mean_average_precision': sum(metrics['average_precision']) / len(metrics['average_precision']) if metrics['average_precision'] else 0
        }
        
        return final_metrics
    
    def _calculate_average_precision(self, retrieved_ids: List[str], relevant_ids: set) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ Average Precision"""
        if not relevant_ids:
            return 0.0
        
        precisions = []
        relevant_count = 0
        
        for i, doc_id in enumerate(retrieved_ids):
            if doc_id in relevant_ids:
                relevant_count += 1
                precision = relevant_count / (i + 1)
                precisions.append(precision)
        
        return sum(precisions) / len(relevant_ids) if precisions else 0.0

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã
class RAGConfigManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ RAG —Å–∏—Å—Ç–µ–º—ã"""
    
    def __init__(self, config_path: str = "rag_config.json"):
        self.config_path = config_path
        self.default_config = {
            "embedding_model": "all-MiniLM-L6-v2",
            "chunk_size": 500,
            "chunk_overlap": 50,
            "collection_name": "default_rag",
            "persist_directory": "./rag_storage",
            "search_results_limit": 5,
            "similarity_threshold": 0.3,
            "batch_size": 100,
            "logging_level": "INFO"
        }
        self.config = self.load_config()
    
    def load_config(self) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        try:
            if os.path.exists(self.config_path):
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                for key, value in self.default_config.items():
                    if key not in config:
                        config[key] = value
                return config
            else:
                return self.default_config.copy()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            return self.default_config.copy()
    
    def save_config(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        try:
            with open(self.config_path, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
    
    def update_config(self, updates: Dict):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        self.config.update(updates)
        self.save_config()
    
    def get(self, key: str, default=None):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        return self.config.get(key, default)

# –ü—Ä–∏–º–µ—Ä –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
class FullRAGSystem:
    """–ü–æ–ª–Ω–∞—è RAG —Å–∏—Å—Ç–µ–º–∞ —Å–æ –≤—Å–µ–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏"""
    
    def __init__(self, config_path: str = "rag_config.json"):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self.config_manager = RAGConfigManager(config_path)
        config = self.config_manager.config
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Å–∏—Å—Ç–µ–º—É
        self.rag = AdvancedRAGPipeline(
            collection_name=config['collection_name'],
            persist_directory=config['persist_directory'],
            embedding_model=config['embedding_model']
        )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.data_manager = DataIngestionManager(self.rag)
        self.analytics = RAGAnalytics(self.rag)
        self.web_interface = RAGWebInterface(self.rag, self.analytics)
        self.benchmarking = RAGBenchmarking(self.rag)
        
        print("üöÄ –ü–æ–ª–Ω–∞—è RAG —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!")
    
    def ingest_directory(self, directory_path: str, file_extensions: List[str] = None):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        if file_extensions is None:
            file_extensions = ['.txt', '.pdf', '.docx', '.json', '.csv']
        
        directory = Path(directory_path)
        if not directory.exists():
            raise Exception(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {directory_path} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        
        documents = []
        
        for file_path in directory.rglob('*'):
            if file_path.is_file() and file_path.suffix.lower() in file_extensions:
                try:
                    if file_path.suffix.lower() == '.txt':
                        content = self.data_manager.load_from_text_file(str(file_path))
                        doc = Document(
                            id=str(file_path.stem),
                            content=content,
                            metadata={'source_file': str(file_path), 'file_type': 'text'}
                        )
                        documents.append(doc)
                    
                    elif file_path.suffix.lower() == '.pdf' and PDF_AVAILABLE:
                        content = self.data_manager.load_from_pdf(str(file_path))
                        doc = Document(
                            id=str(file_path.stem),
                            content=content,
                            metadata={'source_file': str(file_path), 'file_type': 'pdf'}
                        )
                        documents.append(doc)
                    
                    elif file_path.suffix.lower() == '.docx' and DOCX_AVAILABLE:
                        content = self.data_manager.load_from_docx(str(file_path))
                        doc = Document(
                            id=str(file_path.stem),
                            content=content,
                            metadata={'source_file': str(file_path), 'file_type': 'docx'}
                        )
                        documents.append(doc)
                    
                    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω —Ñ–∞–π–ª: {file_path.name}")
                    
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_path.name}: {e}")
        
        if documents:
            self.rag.add_documents_batch(documents)
            print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ {directory_path}")
        else:
            print("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
    
    def create_web_interface(self, output_path: str = "rag_interface.html"):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
        self.web_interface.save_interface(output_path)
        print(f"üåê –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å–æ–∑–¥–∞–Ω: {output_path}")
    
    def run_performance_test(self):
        """–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        test_queries = [
            "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
            "–≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö",
            "–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞",
            "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç",
            "Python –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ"
        ]
        
        print("üß™ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
        results = self.benchmarking.benchmark_search_performance(test_queries)
        
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {results['avg_time']:.3f}s")
        print(f"   –°–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π –∑–∞–ø—Ä–æ—Å: {results['fastest_query']} ({results['fastest_time']:.3f}s)")
        print(f"   –°–∞–º—ã–π –º–µ–¥–ª–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {results['slowest_query']} ({results['slowest_time']:.3f}s)")
        
        return results
    
    def get_system_status(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã"""
        collection_stats = self.rag.get_collection_stats()
        query_stats = self.analytics.get_query_stats()
        content_analysis = self.analytics.analyze_collection_content()
        
        return {
            'collection_stats': collection_stats,
            'query_stats': query_stats,
            'content_analysis': content_analysis,
            'config': self.config_manager.config
        }

# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
if __name__ == "__main__":
    print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–Ω–æ–π RAG —Å–∏—Å—Ç–µ–º—ã...")
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—É—é —Å–∏—Å—Ç–µ–º—É
    full_system = FullRAGSystem()
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_docs = [
        Document(
            id="advanced_doc_1",
            content="–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ RAG –≤–∫–ª—é—á–∞—é—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Ñ–∞–π–ª–æ–≤, –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.",
            metadata={"category": "advanced", "topic": "rag_features"}
        ),
        Document(
            id="advanced_doc_2", 
            content="–°–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞, –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–±–æ—Ç—É –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.",
            metadata={"category": "monitoring", "topic": "analytics"}
        )
    ]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    full_system.rag.add_documents_batch(test_docs)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
    print("\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞...")
    results = full_system.rag.search("–∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ RAG", n_results=2)
    for i, result in enumerate(results):
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç {i+1}: {result.content[:100]}... (—Å—Ö–æ–∂–µ—Å—Ç—å: {result.similarity_score:.3f})")
    
    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
    print("\nüìä –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã:")
    status = full_system.get_system_status()
    print(json.dumps(status, indent=2, ensure_ascii=False))
    
    # –°–æ–∑–¥–∞–µ–º –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    full_system.create_web_interface()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    performance_results = full_system.run_performance_test()
    
    print("\n‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.")card">
                        <h3>–î–æ–∫—É–º–µ–Ω—Ç—ã</h3>
                        <div id="docCount">–ó–∞–≥—Ä—É–∑–∫–∞...</div>
                    </div>
                    <div class="stat-
